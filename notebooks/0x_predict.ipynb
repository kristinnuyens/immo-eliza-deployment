{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21d9dd42",
   "metadata": {},
   "source": [
    "IMPORTS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9f2519e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a9f78c",
   "metadata": {},
   "source": [
    "UPDATE the below paths for your INPUT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed92926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# INPUT = \"../data/processed/immo_train_data.csv\"\n",
    "INPUT = \"../data/processed/immo_test_data.csv\"\n",
    "df = pd.read_csv(INPUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442fc02a",
   "metadata": {},
   "source": [
    "PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "30451848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess data\n",
    "def preprocess(df, target='price', fit=True, preprocessor=None, save_path='../data/processed/df_ml_ready.csv'):\n",
    "    # Copy input\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # Target\n",
    "    y = df_copy[target]\n",
    "\n",
    "    # Calculate & add price per sqm\n",
    "    df_copy['price_per_sqm'] = y / df_copy['total_area_sqm']\n",
    "    df_copy['price_per_sqm'].replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "    # EPC mapping\n",
    "    epc_mapping = {\n",
    "        \"Flanders\": {\"A+\": \"excellent\", \"A\": \"excellent\", \"B\": \"good\",\n",
    "                     \"C\": \"poor\", \"D\": \"poor\", \"E\": \"bad\", \"F\": \"bad\"},\n",
    "        \"Brussels-Capital\": {\"A\": \"excellent\", \"B\": \"good\", \"C\": \"good\",\n",
    "                              \"D\": \"poor\", \"E\": \"poor\", \"F\": \"bad\", \"G\": \"bad\"},\n",
    "        \"Wallonia\": {\"A++\": \"excellent\", \"A+\": \"excellent\", \"A\": \"good\",\n",
    "                     \"B\": \"good\", \"C\": \"poor\", \"D\": \"poor\", \"E\": \"poor\",\n",
    "                     \"F\": \"bad\", \"G\": \"bad\"}\n",
    "    }\n",
    "    df_copy['epc_recoded'] = df_copy.apply(\n",
    "        lambda row: epc_mapping.get(row['region'], {}).get(row['epc'], 'MISSING'),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Column groupings\n",
    "    binary_flags = ['fl_furnished', 'fl_open_fire', 'fl_terrace',\n",
    "                    'fl_garden', 'fl_swimming_pool', 'fl_floodzone', 'fl_double_glazing']\n",
    "    numeric_to_scale = ['construction_year', 'total_area_sqm', 'surface_land_sqm',\n",
    "                        'nbr_frontages', 'terrace_sqm', 'garden_sqm',\n",
    "                        'primary_energy_consumption_sqm', 'nbr_bedrooms', 'price_per_sqm']\n",
    "    categorical_cols = ['property_type', 'subproperty_type', 'region', 'province',\n",
    "                        'equipped_kitchen', 'state_building', 'heating_type', 'epc_recoded']\n",
    "\n",
    "    # Transformers\n",
    "    continuous_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    binary_transformer = 'passthrough'\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "    # ColumnTransformer\n",
    "    if preprocessor is None and fit:\n",
    "        preprocessor = ColumnTransformer(transformers=[\n",
    "            ('num_scaled', continuous_transformer, numeric_to_scale),\n",
    "            ('bin_flags', binary_transformer, binary_flags),\n",
    "            ('cat', categorical_transformer, categorical_cols)\n",
    "        ], remainder='passthrough')\n",
    "\n",
    "    # Fit/transform or just transform\n",
    "    if fit:\n",
    "        X_transformed = preprocessor.fit_transform(df_copy)\n",
    "    else:\n",
    "        X_transformed = preprocessor.transform(df_copy)\n",
    "\n",
    "    # Feature names\n",
    "    cat_features = preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_cols)\n",
    "    scaled_features = [f\"{col}_scaled\" for col in numeric_to_scale]\n",
    "    all_features = scaled_features + binary_flags + cat_features.tolist() + \\\n",
    "                   [col for col in df_copy.columns if col not in numeric_to_scale + binary_flags + categorical_cols]\n",
    "\n",
    "    # Build DataFrame\n",
    "    df_final = pd.DataFrame(X_transformed, columns=all_features)\n",
    "\n",
    "    # Convert all to numeric and fill NaNs\n",
    "    df_numeric = df_final.apply(pd.to_numeric, errors='coerce')\n",
    "    df_numeric = df_numeric.fillna(df_numeric.median())\n",
    "\n",
    "    # Drop columns not needed for ML\n",
    "    columns_to_drop = [\n",
    "        'id', 'construction_year', 'total_area_sqm', 'surface_land_sqm', 'property_type',\n",
    "        'subproperty_type', 'nbr_frontages', 'terrace_sqm', 'garden_sqm', 'primary_energy_consumption_sqm',\n",
    "        'nbr_bedrooms', 'price_per_sqm', 'epc', 'locality'\n",
    "    ]\n",
    "    df_ml_ready = df_numeric.drop(columns=[col for col in columns_to_drop if col in df_numeric.columns])\n",
    "\n",
    "    # Save to CSV\n",
    "    os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "    df_ml_ready.to_csv(save_path, index=False)\n",
    "\n",
    "    # Return ML-ready DataFrame and fitted preprocessor\n",
    "    return df_ml_ready, preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_xgb_top20(df_ml_ready, model_path=\"../models/best_xgb_model_top20.pkl\", target_col='price', cols_to_remove=['price_per_sqm_scaled']):\n",
    "    # Load trained model\n",
    "    xgb_top20 = joblib.load(model_path)\n",
    "    \n",
    "    # Separate target and features\n",
    "    y_test = df_ml_ready[target_col]\n",
    "    X_test = df_ml_ready.drop(columns=[target_col], errors='ignore')\n",
    "    \n",
    "    # Remove unwanted columns\n",
    "    X_test = X_test.drop(columns=[c for c in cols_to_remove if c in X_test.columns], errors='ignore')\n",
    "    \n",
    "    # Keep only the top 20 features that the model was trained on\n",
    "    top20_features = xgb_top20.get_booster().feature_names  # will match training top20\n",
    "    X_test_top20 = X_test[top20_features]\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = xgb_top20.predict(X_test_top20)\n",
    "    \n",
    "    # Metrics\n",
    "    metrics = {\n",
    "        \"test_R2\": r2_score(y_test, y_pred),\n",
    "        \"test_RMSE\": np.sqrt(mean_squared_error(y_test, y_pred)),\n",
    "        \"test_MAE\": mean_absolute_error(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0720e842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_R2: 0.5118\n",
      "test_RMSE: 291438.8233\n",
      "test_MAE: 142617.0701\n"
     ]
    }
   ],
   "source": [
    "# COMBINED FUNCTION\n",
    "# Preprocess input data\n",
    "df_ml_ready, preprocessor = preprocess(df, fit=True, save_path='../data/processed/df_ml_ready.csv')\n",
    "\n",
    "# Load saved XGBoost top-20 model\n",
    "xgb_model = joblib.load(\"../models/best_xgb_model_top20.pkl\")\n",
    "\n",
    "# Test model on preprocessed data\n",
    "metrics, y_pred = test_xgb_top20(df_ml_ready, model_path=\"../models/best_xgb_model_top20.pkl\")\n",
    "\n",
    "# Print metrics\n",
    "for k, v in metrics.items():\n",
    "    print(f\"{k}: {v:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
